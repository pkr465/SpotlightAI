# OTT Promo Agent

An agentic workflow (LangGraph + LangChain) for automated promo generation on OTT platforms.
It ingests existing content, selects highlights, writes scripts/taglines, assembles/renders promos,
personalizes variants, and closes the loop with analytics for continuous optimization.


## Core ideas

- **Graph-first orchestration** with LangGraph for clarity, retries, and conditional routing.
- **Separation of concerns**: node logic in `graph/nodes`, infra/model adapters in `tools`, prompts in `agents`.
- **Observability** hooks to push metrics to your analytics store.
- **A/B testing** and **personalization** built-in.
- **Stateless API** with persisted artifacts in object storage (S3/GCS/Azure Blob).

See code comments in each file for integration notes.

‚∏ª

# High-level design

## Goals
	‚Ä¢	Autonomously generate short promos from long-form OTT assets.
	‚Ä¢	Pick emotionally engaging highlights, write scripts/taglines, assemble edits, and export in common aspect ratios.
	‚Ä¢	Personalize variants per audience/locale; run A/B tests; close the loop with analytics.

## Agentic workflow (LangGraph)
	1.	ingest ‚Üí fetch asset to local cache; record metadata.
	2.	transcode ‚Üí (optional) normalize to mezzanine (codec/framerate/audio).
	3.	asr ‚Üí transcribe/align subtitles (e.g., Whisper) and attach text cues.
	4.	scene_detect ‚Üí rough scene boundaries/duration for downstream passes.
	5.	sentiment ‚Üí emotion/sentiment/energy time-series over the timeline.
	6.	highlight_rank ‚Üí peak-picking + constraints; cut n best micro-segments.
	7.	script_gen ‚Üí LLM writes a 15‚Äì30s script, taglines, SEO keywords.
	8.	edit_assemble ‚Üí assemble highlight clips (concat in stub; real impl adds titles, overlays, music ducking).
	9.	render ‚Üí export AR variants (9:16, 1:1, 16:9), loudness targets, bitrates.
	10.	qc ‚Üí guardrails: duration, silence/black detection, loudness, safe words.
	11.	personalize ‚Üí LLM rewrites script/taglines for each audience/locale.
	12.	ab_test ‚Üí generate test hypotheses + metrics; name variants.
	13.	publish ‚Üí write master + variants to storage (S3/GCS/local).
	14.	analytics ‚Üí emit events (CTR/CVR hooks) and persist feedback.

The repo includes this exact graph with async nodes and typed state. Swap the stubs with your production adapters.

## Key components & where they live
	‚Ä¢	Graph orchestration: src/graph/builder.py, nodes in src/graph/nodes/*
	‚Ä¢	Typed state: src/graph/state.py (Pydantic v2)
	‚Ä¢	LLM clients: src/agents/llm.py (OpenAI or Anthropic, auto-selects via env)
	‚Ä¢	Prompts: src/agents/prompts.py (script, personalization, A/B hypotheses)
	‚Ä¢	Infra adapters: src/tools/storage.py, src/tools/video.py, src/tools/nlp.py, src/tools/analytics.py
	‚Ä¢	Service API: src/app.py (FastAPI) + src/api/routers.py (POST /run)
	‚Ä¢	Config: src/config.py (loads .env), .env.default provided
	‚Ä¢	Tests: src/tests/test_smoke.py
	‚Ä¢	Runtime: requirements.txt (LangGraph, LangChain, FastAPI, etc.)

‚∏ª

## Folder & file layout (you‚Äôll see this in the zip)

ott-promo-agent/
  README.md
  .env.default
  requirements.txt
  src/
    app.py
    config.py
    api/routers.py
    agents/
      __init__.py
      llm.py
      prompts.py
    graph/
      __init__.py
      builder.py
      state.py
      nodes/
        __init__.py
        ingest.py
        transcode.py
        asr.py
        scene_detect.py
        sentiment.py
        highlight_rank.py
        script_gen.py
        edit_assemble.py
        render.py
        qc.py
        personalize.py
        ab_test.py
        publish.py
        analytics.py
    tools/
      __init__.py
      storage.py
      video.py
      nlp.py
      analytics.py
    tests/
      __init__.py
      test_smoke.py


‚∏ª

## Configuration

## Fill .env.default ‚Üí copy to .env:
	‚Ä¢	LLMs: OPENAI_API_KEY, OPENAI_MODEL (default gpt-4o-mini) or Anthropic ANTHROPIC_API_KEY, ANTHROPIC_MODEL (default claude-3-5-sonnet-latest). The system auto-selects whichever key is present.
	‚Ä¢	Storage: STORAGE_BACKEND (s3|gcs|local), S3_BUCKET/GCS_BUCKET, LOCAL_MEDIA_ROOT
	‚Ä¢	Media tools: FFMPEG_BIN, FFPROBE_BIN
	‚Ä¢	Service: LOG_LEVEL, MAX_WORKERS
	‚Ä¢	Analytics sink settings (stubbed local by default)

‚∏ª

## Run it

python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.default .env  # then edit with your keys/buckets
uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload

Example request:

curl -X POST http://localhost:8000/run -H "Content-Type: application/json" -d '{
  "asset_uri": "s3://bucket/sample.mp4",
  "campaign_id": "cmp_001",
  "audiences": ["genpop","sports_fans"],
  "target_formats": ["9:16","16:9"],
  "show_title": "Road to Glory",
  "logline": "An underdog fights through adversity to win it all."
}'


‚∏ª

## Implementation notes & how to extend

Replace stubs with real intelligence
	‚Ä¢	ASR (nodes/asr.py): swap mock transcript for WhisperX/Whisper large-v3 w/ word-level timestamps; store aligned captions in state.metadata["subtitles"].
	‚Ä¢	Scene detection (nodes/scene_detect.py): use ffprobe + histogram difference or a library like PySceneDetect; populate state.duration_s accurately.
	‚Ä¢	Sentiment/energy (nodes/sentiment.py): run audio energy + music intensity + voice emotion (e.g., a wav2vec/Emotion2Vec head) and visual excitement (shot scale, motion magnitude); aggregate into a per-second score.
	‚Ä¢	Highlight selection (nodes/highlight_rank.py): add constraints (no duplicates, narrative coverage, subtitle density, safety filters) and a learning-to-rank model trained on historical engagement.
	‚Ä¢	Edit/assemble (nodes/edit_assemble.py + render.py): replace concat with:
	‚Ä¢	Motion templates, brand pack (logos, fonts), lower thirds, end slates.
	‚Ä¢	Music bed selection + ducking with side-chain compression.
	‚Ä¢	Aspect-ratio smart crop (saliency tracking) for 9:16, 1:1, 16:9.
	‚Ä¢	Personalization (nodes/personalize.py): adjust CTA copy, tone, and overlays per segment/locale; include regulatory word lists per region.
	‚Ä¢	A/B testing (nodes/ab_test.py): generate variant matrix (hook_alt, CTA_alt, music_alt), auto-name variants, and return metrics to analytics.

Storage & publishing
	‚Ä¢	tools/storage.py is mocked; wire to S3/GCS (boto3 / google-cloud-storage). Persist:
	‚Ä¢	Source mezzanine, intermediate clips, final renders.
	‚Ä¢	JSON sidecars: script.json, variants.json, ab_tests.json.

Analytics/feedback
	‚Ä¢	tools/analytics.py currently logs; replace with Segment, Snowflake, or BigQuery writer.
	‚Ä¢	Add a feedback consumer to retrain highlight ranker and prompt heuristics from real CTR/CVR.

Testing
	‚Ä¢	tests/test_smoke.py runs the full graph with mocks.
	‚Ä¢	Add compute-light unit tests for each node (inputs ‚Üí expected state deltas).

‚∏ª

API surface (FastAPI)
	‚Ä¢	GET /health ‚Üí {"ok": true}
	‚Ä¢	POST /run ‚Üí kicks the agentic workflow with your payload and returns the final PromoState (including published_uri, script_json, and personalized_variants).

‚∏ª

Why this architecture works
	‚Ä¢	Composable graph ‚Üí easy to add/remove nodes (e.g., safety, compliance, brand approvals).
	‚Ä¢	Async, idempotent nodes ‚Üí scale out horizontally; retry safely.
	‚Ä¢	Separation of adapters ‚Üí swap models/providers without touching graph logic.
	‚Ä¢	Typed state ‚Üí consistent contracts across nodes; easier debugging/observability.
	‚Ä¢	Extensibility ‚Üí drop in real CV/audio models, RAG over brand guides, and policy filters.

Great choice üéâ ‚Äî SpotlightAI is clear, professional, and marketing-friendly. Here‚Äôs a polished branding package for you to start using right away:

‚∏ª

‚úÖ Project Identity: SpotlightAI

Tagline Options (pick one or rotate for A/B tests):
	‚Ä¢	‚ÄúShining on moments that matter.‚Äù
	‚Ä¢	‚ÄúAI promos that capture attention.‚Äù
	‚Ä¢	‚ÄúFind. Create. Engage. Automatically.‚Äù

One-line elevator pitch:
SpotlightAI turns hours of OTT content into ready-to-publish promos in minutes, using AI to find highlights, write scripts, and personalize videos for every audience.

‚∏ª

üåü Expanded Description

SpotlightAI is an AI-driven promo generation platform built for OTT marketing teams. It ingests video, audio, and subtitles from large content libraries, then uses deep learning to surface emotional peaks and audience-resonant moments. With built-in scriptwriting, automated editing, and personalization, SpotlightAI produces engaging promos at scale ‚Äî tailored for different demographics, platforms, and formats. The system continuously learns from analytics (views, clicks, conversions) to refine future campaigns, enabling faster A/B testing and higher ROI.

‚∏ª

üìä Key Value Props for Pitch Deck
	‚Ä¢	Faster: Create promos in hours instead of weeks.
	‚Ä¢	Cheaper: Cut manual editing and scriptwriting costs by up to 70%.
	‚Ä¢	Smarter: AI selects the most engaging moments automatically.
	‚Ä¢	Personalized: Tailor promos for audiences, regions, and platforms.
	‚Ä¢	Data-driven: Analytics feedback loop improves results over time.

‚∏ª

üé® Visual Branding Concept (suggestions)
	‚Ä¢	Logo motif: A spotlight beam forming the letter S, or a play button inside a glowing halo.
	‚Ä¢	Primary colors: Deep violet / midnight blue (trust + creativity), accented with neon yellow (energy + attention).
	‚Ä¢	Typography: Bold sans-serif (modern tech) for ‚ÄúSpotlight‚Äù, lighter humanist sans for ‚ÄúAI‚Äù.
	‚Ä¢	Style: Dynamic, cinematic feel ‚Äî reflecting both media creativity and AI intelligence.

‚∏ª